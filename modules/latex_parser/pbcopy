```python latex_content_parser.py
import pandoc
import os
import logging

# Configure logging
logger = logging.getLogger(__name__)


def parse_latex_to_markdown(path: str) -> str:
    """
    Parse LaTeX content to Markdown using Pandoc.
    If a directory is provided, it will first find the main tex file in that directory.

    Args:
        path (str): Path to either a .tex file or a directory containing tex files

    Returns:
        str: Markdown content

    Raises:
        FileNotFoundError: If no main tex file is found in the directory
        pandoc.PandocError: If Pandoc conversion fails
        OSError: If changing directory or file access fails
    """
    # Check if input is a directory
    if os.path.isdir(path):
        logger.debug(f"Finding main tex file in directory: {path}")
        file_path = find_main_tex_file(path)
        if file_path is None:
            logger.error(f"No main tex file found in directory: {path}")
            raise FileNotFoundError(f"No main tex file found in directory: {path}")
        logger.info(f"Found main tex file: {file_path}")
    else:
        file_path = path
        if not os.path.exists(file_path):
            logger.error(f"File does not exist: {file_path}")
            raise FileNotFoundError(f"File does not exist: {file_path}")

    # Get absolute path and directory of the input file
    abs_path = os.path.abspath(file_path)
    working_dir = os.path.dirname(abs_path)

    # Store current directory
    original_dir = os.getcwd()

    try:
        # Change to the LaTeX file's directory
        logger.debug(f"Changing to directory: {working_dir}")
        os.chdir(working_dir)

        # Convert LaTeX to Markdown using the file name only
        try:
            logger.debug(f"Converting {os.path.basename(abs_path)} from LaTeX to Markdown")
            doc = pandoc.read(file=os.path.basename(abs_path), format="latex")
            markdown_content = pandoc.write(doc, format="markdown")
            logger.info(f"Successfully converted {os.path.basename(abs_path)} to Markdown")
            return markdown_content
        except Exception as e:
            logger.error(f"Pandoc conversion failed: {str(e)}")
            raise
    except Exception as e:
        logger.error(f"Error during LaTeX to Markdown conversion: {str(e)}")
        raise
    finally:
        # Always change back to original directory
        logger.debug(f"Changing back to original directory: {original_dir}")
        os.chdir(original_dir)


def find_main_tex_file(directory: str) -> str:
    """
    Find the main .tex file in the given directory by looking for \begin{document}.
    Searches through the current directory and all subdirectories.

    Args:
        directory (str): The directory to search in

    Returns:
        str: Path to the main tex file, or None if not found

    Note:
        The function identifies the main tex file by searching for '\begin{document}'
        in the file content, which is a standard indicator of the main LaTeX document.
    """
    logger.debug(f"Searching for main tex file in {directory}")
    for root, _, files in os.walk(directory):
        for file in files:
            if file.endswith(".tex"):
                file_path = os.path.join(root, file)
                try:
                    logger.debug(f"Checking file: {file_path}")
                    with open(file_path, "r", encoding="utf-8") as f:
                        content = f.read()
                        if r"\begin{document}" in content:
                            logger.info(f"Found main tex file: {file_path}")
                            return file_path
                except UnicodeDecodeError:
                    logger.warning(f"Unicode decode error in file: {file_path}")
                    continue
                except IOError as e:
                    logger.warning(f"IO error reading file {file_path}: {str(e)}")
                    continue
    logger.warning(f"No main tex file found in directory: {directory}")
    return None


if __name__ == "__main__":
    # Configure logging for script execution
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")

    # Example usage
    folder_path = "../retriever/arxiv/Papers/1706.03762v7.Attention_Is_All_You_Need"  # Replace with your LaTeX file path
    try:
        file_path = find_main_tex_file(folder_path)
        if file_path:
            markdown_content = parse_latex_to_markdown(file_path)
            print(f"Successfully converted LaTeX to Markdown, length: {len(markdown_content)}")
            # Uncomment to save to file
            # with open("./output.md", "w") as f:
            #    f.write(markdown_content)
        else:
            print(f"No main tex file found in {folder_path}")
    except Exception as e:
        print(f"Error: {str(e)}")
```

```python main.py
import argparse
import json
import sys
import os
import logging

# Add the grandparent directory (backend) to the Python path
# to allow importing modules like modules.latex_parser
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
grandparent_dir = os.path.dirname(parent_dir)
sys.path.append(grandparent_dir)

# Configure logging for the script itself
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

try:
    from modules.latex_parser import latex_content_parser
    from modules.latex_parser import reference_parser

    # Ensure pandoc is available
    import pandoc
except ImportError as e:
    logger.error(f"Failed to import required modules: {e}")
    print(json.dumps({"error": f"Failed to import required modules: {e}"}), file=sys.stderr)
    sys.exit(1)
except FileNotFoundError as e:
    # Pandoc might raise FileNotFoundError if the executable isn't found
    logger.error(f"Pandoc executable not found: {e}")
    print(json.dumps({"error": f"Pandoc executable not found. Please ensure Pandoc is installed and in your PATH. Error: {e}"}), file=sys.stderr)
    sys.exit(1)


def main():
    parser = argparse.ArgumentParser(description="Call LaTeX parser functions.")
    parser.add_argument("--function", required=True, choices=["parse_latex_to_markdown", "extract_references"], help="The function to call.")
    parser.add_argument("--path", help="Path to the .tex file or directory for parsing to Markdown.")
    parser.add_argument("--source_dir", help="Path to the source directory for extracting references.")

    args = parser.parse_args()

    try:
        result = None
        if args.function == "parse_latex_to_markdown":
            if not args.path:
                raise ValueError("--path is required for parse_latex_to_markdown")
            logger.info(f"Calling parse_latex_to_markdown with path: {args.path}")
            result = latex_content_parser.parse_latex_to_markdown(args.path)
        elif args.function == "extract_references":
            if not args.source_dir:
                raise ValueError("--source_dir is required for extract_references")
            logger.info(f"Calling extract_references with source_dir: {args.source_dir}")
            result = reference_parser.extract_references(args.source_dir)

        # Print the result as JSON to stdout
        # For markdown, just print the string; for references, dump the list/dict
        if args.function == "parse_latex_to_markdown":
            print(json.dumps({"markdown": result}))  # Wrap markdown in a JSON object
        else:
            print(json.dumps(result))

    except FileNotFoundError as e:
        logger.error(f"File not found error during {args.function}: {e}")
        print(json.dumps({"error": f"File or directory not found: {e}", "type": "FileNotFoundError"}), file=sys.stderr)
        sys.exit(1)
    except pandoc.PandocError as e:
        logger.error(f"Pandoc conversion error: {e}")
        print(json.dumps({"error": f"Pandoc conversion failed: {e}", "type": "PandocError"}), file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        logger.exception(f"An unexpected error occurred in function '{args.function}'")
        print(json.dumps({"error": f"An error occurred in function '{args.function}': {e}", "type": type(e).__name__}), file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
```

```python reference_parser.py
#!/usr/bin/env python3
"""
Reference Parser Module for ArXiv Papers

This module provides functionality to extract and parse bibliographic references from LaTeX and BibTeX files
typically found in ArXiv paper sources. It can handle both traditional BibTeX (.bib) files and \bibitem
entries embedded within LaTeX (.tex) documents, extracting structured information about each reference.

The parser is designed to be extensible, allowing for additional reference formats to be added in the future.
It attempts to extract as much metadata as possible, including authors, titles, journals, years, DOIs, URLs, etc.

Usage examples:
    # Extract all references from a paper directory
    references = extract_references('/path/to/paper/directory')

    # Parse a specific BibTeX file
    parser = ReferenceParser()
    entries = parser.parse_bibtex_file('/path/to/bibliography.bib')

    # Parse a specific LaTeX file with bibliography
    parser = ReferenceParser()
    entries = parser.parse_latex_bibliography('/path/to/paper.tex')
"""

import os
import re
import logging
import json
from typing import Dict, List, Optional, Any

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


class ReferenceEntry:
    """
    Class representing a bibliographic reference entry.

    This class stores structured information about a bibliographic reference,
    including its identifier, type, and various metadata fields (author, title, etc.).
    """

    def __init__(self, ref_id: str, ref_type: str):
        """
        Initialize a reference entry.

        Args:
            ref_id: The identifier of the reference (e.g., citation key)
            ref_type: The type of reference (article, book, misc, etc.)
        """
        self.id = ref_id
        self.type = ref_type
        self.fields: Dict[str, str] = {}

    def add_field(self, field_name: str, field_value: str):
        """
        Add a field to the reference entry.

        Args:
            field_name: Name of the field (e.g., author, title, year)
            field_value: Value of the field
        """
        self.fields[field_name] = field_value

    def get_field(self, field_name: str) -> Optional[str]:
        """
        Get the value of a field, or None if not present.

        Args:
            field_name: Name of the field to retrieve

        Returns:
            The field value, or None if the field does not exist
        """
        return self.fields.get(field_name)

    def to_dict(self) -> Dict[str, Any]:
        """
        Convert the reference entry to a dictionary.

        Returns:
            Dictionary representation of the reference entry
        """
        result = {
            "id": self.id,
            "type": self.type,
        }
        result.update(self.fields)
        return result

    def __str__(self) -> str:
        """
        Return a string representation of the reference entry.

        Returns:
            A readable string representation of the reference
        """
        fields_str = ", ".join(f"{k}={v}" for k, v in self.fields.items())
        return f"ReferenceEntry(id={self.id}, type={self.type}, fields={{{fields_str}}})"


class ReferenceParser:
    """
    Parser for extracting references from LaTeX and BibTeX files.

    This class provides methods to parse both BibTeX files and LaTeX files
    containing bibliography sections with \bibitem entries.
    """

    # Regular expression to match BibTeX entries
    # Captures entry type, citation key, and the content between braces
    BIBTEX_ENTRY_PATTERN = re.compile(r"@(\w+)\s*{\s*([^,]+),\s*([^@]+?)(?=\s*@|\s*\Z)", re.DOTALL)

    # Regular expression to match BibTeX fields in various formats
    # Handles formats: {...}, "...", numeric values, and plain text values
    BIBTEX_FIELD_PATTERN = re.compile(
        r"(\w+)\s*=\s*{((?:[^{}]|{(?:[^{}]|{[^{}]*})*})*)}|"  # {...} format
        r'(\w+)\s*=\s*"([^"]*)"|'  # "..." format
        r"(\w+)\s*=\s*(\d+(?:\.\d+)?)|"  # numeric value without quotes
        r'(\w+)\s*=\s*([^,\s{}"\n]+)',  # unquoted value until comma, space, or newline
        re.DOTALL,
    )

    # Regular expression to match LaTeX \bibitem entries
    # Captures the optional label, citation key, and content
    BIBITEM_PATTERN = re.compile(r"\\bibitem(?:\[(.*?)\])?\{(.*?)\}(.*?)(?=\\bibitem|\\end\{thebibliography\}|\Z)", re.DOTALL)

    def __init__(self):
        """Initialize the parser with an empty dictionary of entries."""
        # Dictionary to store entries by their ID for deduplication
        self.entries: Dict[str, ReferenceEntry] = {}

    def parse_bibtex_file(self, file_path: str) -> List[ReferenceEntry]:
        """
        Parse a BibTeX file and extract reference entries.

        Args:
            file_path: Path to the BibTeX file

        Returns:
            List of extracted reference entries
        """
        try:
            # Read the file content, ignoring encoding errors
            with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                content = f.read()
            return self.parse_bibtex_content(content)
        except Exception as e:
            logger.error(f"Error parsing BibTeX file {file_path}: {str(e)}")
            return []

    def parse_bibtex_content(self, content: str) -> List[ReferenceEntry]:
        """
        Parse BibTeX content and extract reference entries.

        Args:
            content: BibTeX content as a string

        Returns:
            List of extracted reference entries
        """
        entries = []

        # Find all BibTeX entries using the regex pattern
        matches = self.BIBTEX_ENTRY_PATTERN.finditer(content)
        for match in matches:
            entry_type = match.group(1).lower()  # e.g., article, book, misc
            entry_id = match.group(2).strip()  # citation key
            entry_content = match.group(3).strip()  # content inside braces

            # Create a new reference entry
            entry = ReferenceEntry(entry_id, entry_type)

            # Extract fields with the enhanced pattern
            field_matches = self.BIBTEX_FIELD_PATTERN.finditer(entry_content)
            for field_match in field_matches:
                # Group 1 & 2: {...} format
                # Group 3 & 4: "..." format
                # Group 5 & 6: numeric format
                # Group 7 & 8: plain text format
                if field_match.group(1):
                    field_name = field_match.group(1).lower()
                    field_value = field_match.group(2)
                elif field_match.group(3):
                    field_name = field_match.group(3).lower()
                    field_value = field_match.group(4)
                elif field_match.group(5):
                    field_name = field_match.group(5).lower()
                    field_value = field_match.group(6)
                elif field_match.group(7):
                    field_name = field_match.group(7).lower()
                    field_value = field_match.group(8)
                else:
                    # Should never get here due to regex groups
                    continue

                # Clean field value and add to entry
                entry.add_field(field_name, self._clean_bibtex_value(field_value))

            # Add the raw content for debugging or full access
            entry.add_field("raw_bibtex", f"@{entry_type}{{{entry_id}, {entry_content}}}")

            entries.append(entry)
            self.entries[entry_id] = entry

        return entries

    def parse_latex_bibliography(self, file_path: str) -> List[ReferenceEntry]:
        """
        Parse a LaTeX file and extract \bibitem entries.

        Args:
            file_path: Path to the LaTeX file

        Returns:
            List of extracted reference entries
        """
        try:
            # Read the file content, ignoring encoding errors
            with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                content = f.read()
            return self.parse_latex_bibliography_content(content)
        except Exception as e:
            logger.error(f"Error parsing LaTeX file {file_path}: {str(e)}")
            return []

    def parse_latex_bibliography_content(self, content: str) -> List[ReferenceEntry]:
        """
        Parse LaTeX content and extract \bibitem entries.

        Args:
            content: LaTeX content as a string

        Returns:
            List of extracted reference entries
        """
        entries = []

        # Find all bibitem entries using the regex pattern
        matches = self.BIBITEM_PATTERN.finditer(content)
        for match in matches:
            optional_label = match.group(1)  # May be None if no optional label
            entry_id = match.group(2).strip()  # citation key
            entry_content = match.group(3).strip()  # content after the citation key

            # Create a new reference entry
            entry = ReferenceEntry(entry_id, "bibitem")

            # Keep the optional label if available
            if optional_label:
                entry.add_field("label", optional_label.strip())

            # Extract author, title, and other information using heuristics
            parsed_fields = self._parse_bibitem_content(entry_content)
            for field_name, field_value in parsed_fields.items():
                entry.add_field(field_name, field_value)

            # Add the raw content for debugging or full access
            if optional_label:
                entry.add_field("raw_bibitem", f"\\bibitem[{optional_label}]{{{entry_id}}}{entry_content}")
            else:
                entry.add_field("raw_bibitem", f"\\bibitem{{{entry_id}}}{entry_content}")

            entries.append(entry)
            self.entries[entry_id] = entry

        return entries

    def _parse_bibitem_content(self, content: str) -> Dict[str, str]:
        """
        Parse the content of a bibitem entry using heuristics.

        This method attempts to extract structured information from unstructured bibitem content
        using various heuristics and regular expressions.

        Args:
            content: The content of the bibitem

        Returns:
            Dictionary with parsed fields
        """
        fields = {}

        # Store the raw text (normalized)
        fields["raw_text"] = content.replace("\n", " ").replace("  ", " ").strip()

        # Split by newlines and remove empty lines
        lines = [line.strip() for line in content.split("\n") if line.strip()]

        if not lines:
            return fields

        # First line typically contains authors
        fields["author"] = lines[0].rstrip(".")

        # Second line typically contains the title
        if len(lines) > 1:
            title_line = lines[1].strip()
            # Remove \newblock if present
            title_line = title_line.replace("\\newblock", "").strip()
            fields["title"] = title_line.rstrip(".")

        # Extract journal/booktitle information using various patterns
        journal_patterns = [
            r"\\textit{([^}]+)}",  # \textit{journal}
            r"\\emph{([^}]+)}",  # \emph{journal}
            r"{\\em\s+([^}]+)}",  # {\em journal}
            r"\\em\s+([^,\.]+)",  # \em journal
            r"In\s+{\\\w+\s+([^}]+)}",  # In {\xx journal}
            r"In\s+\\textit{([^}]+)}",  # In \textit{journal}
            r'In\s*[\'"]([^\'"]*)[\'"]\.*',  # In "journal"
            r"(?:In |in ){\\it ([^}]+)}",  # In {\it journal}
            r"(?<=\.)[ \t]+([A-Z][^,\.]*(?:Journal|Proceedings|Transactions|Review|Letters)[^,\.]*)",  # journal name
        ]

        # Try each pattern until we find a match
        for pattern in journal_patterns:
            match = re.search(pattern, content)
            if match:
                fields["journal"] = match.group(1).strip()
                break

        # Extract booktitle for conference papers
        booktitle_patterns = [
            r"In\s+(?:proceedings\s+of|proc\.\s+of|Proc\.\s+of)\s+the\s+([^,\.]+)",  # In proceedings of the CONF
            r"In\s+([^,\.]*(?:Conference|Symposium|Workshop)[^,\.]*)",  # In XYZ Conference
        ]

        # Try each pattern if journal wasn't found
        for pattern in booktitle_patterns:
            match = re.search(pattern, content)
            if match and "journal" not in fields:
                fields["booktitle"] = match.group(1).strip()
                break

        # Extract publisher
        publisher_patterns = [
            r"(?:publisher|Publisher)[\s=:]+([^,\.]+)",  # publisher: XYZ
            r"([^,\.]+?(?:Press|Publishers|Publishing))",  # XYZ Press
        ]

        for pattern in publisher_patterns:
            match = re.search(pattern, content)
            if match:
                fields["publisher"] = match.group(1).strip()
                break

        # Try to extract year
        year_match = re.search(r"\b(19|20)\d{2}\b", content)
        if year_match:
            fields["year"] = year_match.group(0)

        # Try to extract volume
        volume_match = re.search(r"volume\s*[=:]*\s*(\d+)|Vol\.\s*(\d+)|volume\s+(\d+)", content, re.IGNORECASE)
        if volume_match:
            vol = volume_match.group(1) or volume_match.group(2) or volume_match.group(3)
            fields["volume"] = vol

        # Try to extract number/issue
        number_match = re.search(r"number\s*[=:]*\s*(\d+)|No\.\s*(\d+)|issue\s+(\d+)|issue\s*[=:]*\s*(\d+)", content, re.IGNORECASE)
        if number_match:
            num = next((g for g in number_match.groups() if g is not None), None)
            if num:
                fields["number"] = num

        # Try to extract pages
        pages_match = re.search(r"pages\s*[=:]*\s*([\d\-–—]+)|pp\.\s*([\d\-–—]+)", content, re.IGNORECASE)
        if pages_match:
            pages = pages_match.group(1) or pages_match.group(2)
            fields["pages"] = pages.replace("–", "-").replace("—", "-")

        # Extract DOI if available
        doi_match = re.search(r"doi\s*[:=]\s*([^\s,]+)", content, re.IGNORECASE) or re.search(r"https?://(?:dx\.)?doi\.org/([^\s,]+)", content)
        if doi_match:
            fields["doi"] = doi_match.group(1).strip()

        # Extract URL if available
        url_match = re.search(r"\\url{([^}]+)}", content) or re.search(r"https?://[^\s,}]+", content)
        if url_match:
            fields["url"] = url_match.group(1).strip() if "\\url{" in url_match.group(0) else url_match.group(0)

        # Extract arXiv identifier
        arxiv_match = re.search(r"arXiv:([^\s,}]+)", content) or re.search(r"https?://arxiv\.org/abs/([^\s,}]+)", content)
        if arxiv_match:
            fields["arxiv"] = arxiv_match.group(1).strip()

        # Try to identify address/location
        addr_patterns = [
            r"address\s*[=:]\s*([^,\.]+)",  # address: XYZ
            r"([A-Z][a-zA-Z]+,\s+[A-Z]{2,})",  # City, STATE
            r"([A-Z][a-zA-Z]+,\s+[A-Z][a-zA-Z]+)",  # City, Country
        ]

        for pattern in addr_patterns:
            match = re.search(pattern, content)
            if match:
                fields["address"] = match.group(1).strip()
                break

        # Try to identify if it's a book
        if re.search(r"\\textit{([^}]*book[^}]*)}", content, re.IGNORECASE) and "journal" not in fields:
            fields["type"] = "book"

        return fields

    def _clean_bibtex_value(self, value: str) -> str:
        """
        Clean and normalize a BibTeX field value.

        This method replaces LaTeX escape sequences with their Unicode equivalents,
        removes unnecessary braces, and normalizes whitespace.

        Args:
            value: The raw value from BibTeX

        Returns:
            Cleaned and normalized value
        """
        if not value:
            return value

        # Common LaTeX escape sequences and their replacements
        latex_escapes = {
            "\\&": "&",
            '\\"a': "ä",
            '\\"A': "Ä",
            '\\"o': "ö",
            '\\"O': "Ö",
            '\\"u': "ü",
            '\\"U': "Ü",
            "\\`a": "à",
            "\\`A": "À",
            "\\'e": "é",
            "\\'E": "É",
            "\\'a": "á",
            "\\'A": "Á",
            "\\'o": "ó",
            "\\'O": "Ó",
            "\\'u": "ú",
            "\\'U": "Ú",
            "\\'i": "í",
            "\\'I": "Í",
            "\\'{e}": "é",
            "\\'{E}": "É",
            "\\c{c}": "ç",
            "\\c{C}": "Ç",
            "\\~a": "ã",
            "\\~A": "Ã",
            "\\~n": "ñ",
            "\\~N": "Ñ",
            "\\ss": "ß",
            "\\ae": "æ",
            "\\AE": "Æ",
            "\\oe": "œ",
            "\\OE": "Œ",
            "\\textbackslash": "\\",
            "\\textgreater": ">",
            "\\textless": "<",
            "\\$": "$",
            "\\%": "%",
            "\\_": "_",
            "\\#": "#",
            # Greek letter replacements for math mode
            "\\alpha": "alpha",
            "\\beta": "beta",
            "\\gamma": "gamma",
            "\\delta": "delta",
            "\\epsilon": "epsilon",
            "\\zeta": "zeta",
            "\\eta": "eta",
            "\\theta": "theta",
            "\\iota": "iota",
            "\\kappa": "kappa",
            "\\lambda": "lambda",
            "\\mu": "mu",
            "\\nu": "nu",
            "\\xi": "xi",
            "\\pi": "pi",
            "\\rho": "rho",
            "\\sigma": "sigma",
            "\\tau": "tau",
            "\\upsilon": "upsilon",
            "\\phi": "phi",
            "\\chi": "chi",
            "\\psi": "psi",
            "\\omega": "omega",
        }

        # Replace LaTeX escape sequences
        for escape, replacement in latex_escapes.items():
            value = value.replace(escape, replacement)

        # Handle special pattern \"{x} format (for umlauts and accents)
        value = re.sub(
            r"\\\"{\s*([aouiAOUI])\s*}",
            lambda m: "ä"
            if m.group(1).lower() == "a"
            else "ö"
            if m.group(1).lower() == "o"
            else "ü"
            if m.group(1).lower() == "u"
            else "ï"
            if m.group(1).lower() == "i"
            else m.group(0),
            value,
        )

        # Handle math mode content by removing the math delimiters
        # This must happen after the LaTeX escapes are handled
        value = re.sub(r"\$([^$]+)\$", r"\1", value)

        # Remove unnecessary quotes and braces that don't serve as escape sequences
        value = re.sub(r"{([^{}]*)}", r"\1", value)

        # Normalize whitespace
        value = " ".join(value.split())

        return value

    def find_and_parse_references(self, directory_path: str) -> List[ReferenceEntry]:
        """
        Find and parse all reference sources in a directory.

        This method searches for BibTeX files first. If none are found, it looks
        for LaTeX files with bibliography sections.

        Args:
            directory_path: Path to the directory to search

        Returns:
            List of all extracted reference entries
        """
        parsed_entries: List[ReferenceEntry] = []

        # Step 1: Look for BibTeX files first (they're more structured)
        found_bibtex = False
        for root, _, files in os.walk(directory_path):
            for file in files:
                if file.endswith(".bib"):
                    file_path = os.path.join(root, file)
                    entries = self.parse_bibtex_file(file_path)
                    parsed_entries.extend(entries)
                    logger.info(f"Parsed {len(entries)} entries from BibTeX file: {file_path}")
                    found_bibtex = True

        # Step 2: If no BibTeX files were found, look for LaTeX files with bibliography sections
        if not found_bibtex:
            for root, _, files in os.walk(directory_path):
                for file in files:
                    if file.endswith(".tex"):
                        file_path = os.path.join(root, file)
                        try:
                            with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                                content = f.read()

                            # Check if the file contains a bibliography section
                            if "\\begin{thebibliography}" in content:
                                entries = self.parse_latex_bibliography(file_path)
                                parsed_entries.extend(entries)
                                logger.info(f"Parsed {len(entries)} entries from LaTeX bibliography: {file_path}")
                        except Exception as e:
                            logger.error(f"Error reading LaTeX file {file_path}: {str(e)}")

        # Step 3: If still no entries found, try all LaTeX files for bibitems
        if not parsed_entries:
            found_any = False
            for root, _, files in os.walk(directory_path):
                for file in files:
                    if file.endswith(".tex"):
                        file_path = os.path.join(root, file)
                        try:
                            with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                                content = f.read()

                            if "\\bibitem" in content:
                                entries = self.parse_latex_bibliography(file_path)
                                parsed_entries.extend(entries)
                                found_any = True
                                logger.info(f"Parsed {len(entries)} entries from LaTeX file with bibitems: {file_path}")
                        except Exception as e:
                            logger.error(f"Error reading LaTeX file {file_path}: {str(e)}")

            if not found_any:
                logger.warning(f"No bibliography sources found in {directory_path}")

        # Step 4: Remove duplicates based on ID
        unique_entries: Dict[str, ReferenceEntry] = {}
        for entry in parsed_entries:
            unique_entries[entry.id] = entry

        return list(unique_entries.values())


def extract_references(paper_dir: str) -> List[Dict[str, Any]]:
    """
    Extract references from a paper directory.

    This is the main function to use for extracting references from a paper directory.
    It handles finding the appropriate files and parsing them.

    Args:
        paper_dir: Path to the paper directory

    Returns:
        List of dictionaries representing reference entries

    Example:
        >>> references = extract_references('/path/to/arxiv/paper')
        >>> print(f"Found {len(references)} references")
    """
    parser = ReferenceParser()
    entries = parser.find_and_parse_references(paper_dir)
    return [entry.to_dict() for entry in entries]


if __name__ == "__main__":
    import sys
    import json

    if len(sys.argv) != 2:
        print(f"Usage: {sys.argv[0]} <paper_directory>")
        sys.exit(1)

    paper_dir = sys.argv[1]
    references = extract_references(paper_dir)

    print(f"Found {len(references)} references:")

    # Print a sample of the first 5 references in a readable format
    for i, ref in enumerate(references[:5], 1):
        print(f"\n{i}. {ref.get('id', 'Unknown ID')}:")
        if "author" in ref:
            print(f"   Author: {ref['author']}")
        if "title" in ref:
            print(f"   Title: {ref['title']}")
        if "year" in ref:
            print(f"   Year: {ref['year']}")
        if "journal" in ref:
            print(f"   Journal: {ref['journal']}")
        print(f"   Type: {ref.get('type', 'Unknown type')}")

        # Print number of fields extracted
        field_count = len(ref) - 2  # Subtract 'id' and 'type' which are always present
        print(f"   Fields extracted: {field_count}")

    # Save to JSON file for inspection
    output_file = os.path.join(os.path.dirname(paper_dir), "references_extracted.json")
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(references, f, indent=2, ensure_ascii=False)

    print(f"\nAll references saved to {output_file}")
```

